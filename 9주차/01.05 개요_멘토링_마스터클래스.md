# 데일리 스크럼
코테

세훈
```
idx = 1
str(idx) * int()
idx +=1
```

승준
- stack
```
answer += ~~

for i in answer[::-1] :
~~

```

linux
- 18버전이라 파이토치 버전
노션 - 환경통일

# 멘토링
자기소개
- recsys를 왜 골랐는지
	- 하다보니 이렇게 되었습니다.
	- 경험
- 수료 후 목표
	- 이머커스 관련 기업 취업 목표

같이 성장해야함.
level1~2~3 공유

일주일 전에 스케쥴
- 공식멘토링은 코어시간
- 개인멘토링

사전질문
- 해줘야함

2~3주차에 선배캠퍼

의논해보았으면 좋겠는 것
- 통합멘토링
- 대회 공유는 금지

오프라인은 level3
- 트랙별 돌아가면서 날짜 잡힘
- 선착순
- 주제가 주어지지 않고 알아서 공부

level3
- 17~19시 마스터 피드백


쉴 때 한번 고민해볼 것
- 어떤 프로젝트하는 것이 좋을까? 생각
- 많은 목록에서 하나씩 지우기
- 좋은 프로젝트?
	- 많은 고민
	- 기술은 비슷하다
- 수료후에 뭘할까?

질문리스트
- 여기에서 실패해봐라
- 안될 것 같다고 생각하는 것보다는 일단 테스트해봐라.
- dkt 모델 중 성능이 가장 좋은 것?
	- gnn 계열
	- 
- lightgbm
	- leaf
## 데이터의 특성
- lightgcn으로 임베딩하고 그 결과를 다른 모델
- dkt는 catboost가 안좋을것.
- autoencoder기반이 좋을수도.
- 그래프계열을 해볼 것.
	- 실제 추천에서 많이 사용되는 모델.
- 첫번째에서 아쉬웠던 모델을 먼저 사용해보기

## 중요한 것.
- 왜 이게 통했는가?
	- 그것에 대한 감상,분석문
- 못해봤던 것 다해보기

# 마스터 클래스

## DKT Survey 논문 리뷰

## 실험적으로 알려진 팁
- 모든것에 대한 sota논문은 없다
	- 다양한 모델로 실험해보기
		- 다양한 모델을 빠르게 활용하는 연습
환율 예측
- task마다 모델이 달라짐
- sequence 데이터

### 평가 지표
- AUC가 능사인가?
	- 상대적인 비교는 가능하나, 실제에서의 중요한 outlier를 예측하는 데 어려움을 겪음.
	- avg, f1등 다양한 지표와의 비교가 필요.
- 모델들이 지표별로 성능 우위가 다르기 떄문에 여러 평가 지표를 활용해보는 것도 좋음.

### 데이터셋이 변화하는 경우
- 가장 현실적인 성능을 보여주는 것은 f1 score

###  하이퍼파라미터 튜닝
- 필수
- 모델별 성능만큼 튜닝에 따른 성능도 달라짐.

모델 별 튜닝
- 입력값 처리 비교
	- one hot encoding, embedding
- 최대 문항 수 조절
- lr, embedding_size, # layers, attention heads...

encoding, embedding 성능 차이?
- 있을수도 없을수도

maximum attempt 조절
- 한 학생이 푼 문항이 많으면 split, cut or 버리기
- 트랜스포머의 시간복잡도
	- seq_len의 제곱

Seed
- 최적화의 대상은 아님.
- seed ensemble?

Forgetting Behavior - Time & Count
- RT : 동일한 문제를 학습한 이후 경과 시간
- ST :
- TC :

Consistent Regularization

Counter-intuition
- 한 문제를 틀렸는데, 동일한 다음문제를 맞출것이라 예상
reconstruction loss
- 다음문제의 정답여부를 loss로 사용
- regularization term 추가

Pretrain : Embedding
- 정형데이터는 foundation model을 만들기 어려움
- 노드에 집어넣어 finetuning하고자 하는 시도가 있음
- Question - skill 사이의 관계 데이터를 바탕으로 시도

Metric : FP & FN
- AOC와 같은 metric도 중요하지만, 
- 현업에서는 TN,TP는 증가, FP,FN은 감소 시키는 것이 중요(진실과 거짓 구분)
- 일단은 skillset을 갖추는 것이 중요

shaking up
- public과 private의 차이가 존재함.
- robust한 모델을 만들어봅시다.


## 질문

DKT는 개인화인 것 같은데?
- 이렇게 적용해 볼 수 있다는 하나의 예시 문제.
- 게임에서의 강화학습처럼 적절하게 어려운 문제를 제공해주는 것이 실력향상에 도움이 될 수 있을 것. 
- 강화학습 == long term reward를 반영할 수 있다.
	- 여러 활용 방안 중 하나.

현업에서의 앙상블
- why not?
- 많을수록 장애 포인트가 많아지는 것.
- 성능이 정말 중요하다면 할 수 있겠지만, 유지보수, 자원을 고려해서 적절하게 사용

현업에서 도움이 되는 공부 방법?
- 캐글 만능론 : 캐글 O
- 캐글 무용론 : 캐글 X,  현업
- 주니어에게 기대하는 폭에 따라 달라질 것.
	- 경험의 폭이 좁음
	- 그래도 다양하게 해보는 것이 중요.

## 각자의 모델링의 솔루션을 이해하는 것이 좋음.

모델 설계
- 기존의 모델을 활용하여 시작.
	- 기존의 모델에 대한 이해가 있어야 이를 응용할 수 있지 않을까?
	- 기존의 모델을 잘 쓰는 것 자체도 어렵다.

포폴에서는?
- 이것저것 다 해봤다!
- 성능을 높이기 위해 어떻게 고민을 하였다!
	- 협업을 어떻게 했고
	- 문제를 풀기 위해 어떤 가설을 세웠고
- 기본 cs
	- 비전공자 이지만, 자신의 러닝커브를 강조하는 것이 중요


금융 ai에서의 task
- 대출, 신용평가, 거래 및 내부거래 등에 대한 이상탐지
- 마케팅, 환율예측
- ocr..?

금융 취업
- 기본적인 자질?
- 금융에 대한 이해와 관련해서는
	- 이해하기 위해 어떤 이론적 지식을 공부했다 정도
	- 은행의 전반업무 정도
	- 용어(여신과 같은)
- 은바은

지원하는 회사의 데이터 구조를 확인하고, 이를 바탕으로 내가 어떤 부분을 할 수 있을 것이다.
- 은행의 경우 어떻게 데이터를 쌓을 수 있을 것인가?
- 카드, 보험..
	- 신용카드에서의 데이터 : 시간, 고객정보, 금액, 옛 사용정보..
	- 은행 : 예출정보, 금액...
- 이런 것을 바탕으로 자신의 의견을 제시

다른 도메인의 디메리트?
- 경쟁력이 있으면 상관없다.
- 금융공학이면 좋겠? 그러진 않음.

cell
- 각자 다른 stack, 전공
- 팀 단위로 능력을 측정하기 때문에 분야는 다르게 모임.
- 잘하는 것을 시키거나, 경험을 위해 못하는 것을 시키거나.

금융권은 개발자의 지옥이다?
- 경험의 부재일 수도 있고
- 셀바셀
- 실력차이

금융계에서의 트렌드?
- LLM
	- 상담과 같은 기능
- 정형, 추천과 같은 레거시를 더 많이함

레거시 코드
- ai/ml은 파이썬 
- 백엔드는 모르겠음.

보안?
- 망 분리가 되어있음.
- 내부망에서 추가적인 vpc사용

일부는 클라우드 기반으로 진행
- public에 올릴 수 있는 데이터는 올려서
- 대부분은 못 올리긴 함.

ai는 그냥 직장인.
- 인센티브 같은 것은 없음.

DX 전환 키워드?
- 어느정도 부풀려져 있긴한데 틀린말은 아님.
- 프로세스에서 ai는 일부분을 차지
	- 일부기 때문에 성과를 측정하기 어려움
- 완결성
	- 모델링도 중요하지만, 어떻게 결과를 낼 것인가에 대한 것도 중요

imbalance, 이상탐지를 어떻게 하는가?
- -10e-5 ~ -7정도의 불균형에서
- 그래도 sampling하면 지도학습은 되더라.
	- 규모에 따라서 1:1000, 1:10000 비율도 작동은 됨.

스킬셋
- 강의를 잘 들어라
- 모델들을 사용하여 성능을 내기 위해 실행한 모든 것.
	- 모델링, 협업,,,,
- 


마무리?
- 기본 소양
	- 파고드는 능력
	- 성장하는 능력
	- 커뮤니케이션 능력

금요일 : [주간 학습정리](https://www.boostcourse.org/boostcampaitech6/forums/384196) 