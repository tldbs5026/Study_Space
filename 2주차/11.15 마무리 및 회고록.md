
# 1. 오늘 마무리 지어야 할 일
- 오늘 강의 내용 + 과제 진행한 것 정리하기
- 

# 2. 내일 해야할 일
- 오늘 미처 마무리하지 못한 과제 마무리
- 강의 나머지 분량 마무리
- 금요일을 대비한 심화 과제 마무리하기
- 과제 1의 옵션도 시간이 나면 확인.


# 3. 오늘 들은 강의 정리
텐서보드
- 시각화 툴
- 학습 그래프, metric, 학습 결과 시각화
- 추가적으로 scalar, graph, histogram, image등을 시각적으로 확인 가능
- SummaryWriter 명령어로 실행가능
	- scalar : add_scalar
	- 딕셔너리의 형태로 여러개 한번에 지정가능
	- 히스토그램 : add_histrogram
	- 하이퍼파라미터 : h_params

Weight & Bias
- 머신러닝 실험을 지원하기 위한 툴
- wandb
- 사이트에 연동하여 진척도를 공유할 수 있음.


Model Parallel
- 다중 gpu에 학습 분산
- 모델을 나누어 학습
- alexnet부터 시작됨
- 모델의 병목, 파이프라인의 어려움
- sequential한 모델 뒤에 to('cuda:n')으로 다중 cuda의 번호를 지정하여 할당
	- 연결은 seq2(self.seq1(x).to('cuda:1'))과 a에 할당된 모델을 b에 할당함으로써 합침 
Data Parallel
- 데이터를 나누어 gpu에 할당 후 결과의 평균
- minibatch와 유사하지만 다중 gpu에서 실행
- DataParallel : 단순히 데이터를 분배한 후 평균
	- nn.DataParallel(model)
	-  + loss.mean().backward()
- DistributedDataParallel : 각 cpu마다 process를 생성하여 개별 gpu에 할당
	1. 샘플러를 정의
		- torch.utils.data.distributed.DistributedSampler(train_data)
		- + utils.data.DataLoader(~~~)
	2. 이후 main에서 cuda.device_count()로 gpu 개수 정의
		torch.multiprocessing.spawn으로 다중작업 생성
	3. main_worker 함수
		- torch.distributed.init_process_group으로 멀티프로세싱 통신 규약 정의
		- torch.cuda.set_device(gpu)
		- model = model.cuda(gpu)
		- model = torch.nn.parallel.DistributedDataParallel(model, debice_ids=[gpu]) 
		- : Distributed DataParallel 정의


num_workers
- 데이터를 불러올 때 사용하는 서브 프로세스 개수
- 무작정 높이면 cpu와 gpu 사이에 병목현상이 생김

collate_fn
- 배치 단위 데이터를 같은 피쳐, 라벨로 묶어 데이터 사이즈를 맞추기 위해서 사용
- 기본적으로 DataLoader에서 실행되는 옵션이기 때문에 collate_fn 함수 내부에서는 DataLoader의 옵션을 그대로 사용한다.
- 만약 로더의 batch_size가 2면, collate_fn함수 내부에서도 batch_size가 2개로 진행된다.

pin_memory
- True : 텐서를 CUDA 고정 메모리에 할당

drop_last
- batch 단위로 데이터를 불러올 때, 마지막 batch의 길이가 다를 때 제거함으로써 loss를 구하기 쉽게 해줌

Torchvision의 transform
- Resize : 크기 재정의
- crop : 지정(임의) 위치 자르기
- rotation : 회전

transform의 Compose
- 여러 transform을 하나로 묶어서 처리

그 외의 transform
- dir(transform)으로 확인가능

이미지 데이터 클래스 데이터셋 가져오기
- torchvision.datasets.(MNIST/CIFAR10)('경로', train여부. transform지정, download 여부)

torchtext
- 텍스트 데이터셋 가져오기
- 텍스트 셋은 tokenizer 이용해서 단어를 분리하여 임베딩한다.

# 4. 회고록
- 
- 추가적으로 과제를 진행하는데 있어 평소 코드를 다룰때 하던 실수가 나와서 과제를 진행하는데 지체가 되었다. 금방 발견할 수 있는 실수지만, 내가 익숙하지 않은 상황에서 여유가 없으니 조그마한 실수가 정신적인, 체력적인 리소스를 잡아먹는 다는 것이 유쾌한 기분은 아니었다. 추가적으로 과제를 진행하고 싶지만, 이럴때는 바쁘더라도 평소하던 작업량을 줄이고 휴식을 취해서 다음날 마무리를 짓고 다음으로 넘어가는 것도 좋다고 생각한다.  