
# 어디까지 공부했는가
- 과제 2 - 타이타닉전까지
- 7강까지 진행 후 과제 1~2 진행 


# 할만할 말
- data_loader에서의 batch_size를 확인합시다!
- 전체적인 흐름을 이해하는 것도 좋지만, 익숙해지면 디테일한 부분도 같이 파고들어갑시다
- pytorch의 concat은 cat()이라는 명령어

# 강의리뷰
훈
	- backward
		- zero_grad()
		- get loss
		- get gradients
		- update parameters
	- __getitem__
		- index가 주어졌을 때 Data를 어떻게 반환할지 선언
현주
	- transforms, dataset, dataloader를 예전 프로젝트를 바탕으로 복기
		- wandb를 사용하여 기록한 것을 확인하는 용도로 사용했음
		- tensorboard 와 wandb 둘을 실제로 사용하면서 비교해보면 좋겠다
	- vscode로 깃허브 보는법  : github1s.com~~
재원
	- gather
		- 결괏값이 이상하면 document를 확인하는 것이 정답을 찾는데 도움이 될 것이다.

재권
	- DataLoader
		- 4강 : 데이터셋 generator
		- 5강  : 데이터로더 iterator
	- iterator : iterable한 객체를 반환
	- generator : iterator의 특별한 경우
		- 리턴을 하지않고 yield로 결과값을 냄
		- 메모리 경제성이 뛰어남
	- dataloader는 iterable한 객체로 iterator를 갖고 있다.
	- 



# 모더레이터 발표
gpt 잘 다루는 방법
- 명확한 지침 작성하기 : 질문에 세부 정보 제시
- 참고 문헌 제공
- 간단한 하위 작업으로 나눈 후 통합하기
- 생각할 시간주기
- 외부 도구 사용하기 : 임베딩 기반 검색을 활용
- 변경 사항을 체계적으로 테스트하기
- 
발표 깊이는 이정도가 적당하다고 피드백 받음_10분정도?_
pro는 session에 따라 누적됨



# 해야할 일
- 오늘 강의 + 과제 진행 것 중간 정리

# 회고록
- 모더레이터로써 발표를 진행하기로 하였는데, 너무 가벼운 주제를 선정한 것 아닌가하는 미안함이 있었지만 그래도 팀원들이 호응을 어느정도 해주어서 나쁘진 않았다고 생각한다. 그 이후 간단한 잡답을 하고 두런두런에 참석하기 위해 휴식을 취한 후 진행하고자 평소보다 다소 빠르게 마무리 지었다. 