
# 일정
- 스페셜 피어세션 1500-1600 : 2조
- 피어세션 1600-1700
- 오피스아워 1700-1800
- 주간학습정리 ~2100
- 팀회고 ~2100

# 데일리 스크럼


# 스페셜 피어세션

	- 백엔드 하다가옴
	- 간단한 발표, 수다
	- 부스트코칭 스터치 : MLops aws eks?
	- 당근, 카카오 인턴 지원

멘토링 할때 다른 조랑 변경해서
통합 멘토링

- 일단 프로젝트보고 다들 결정하지 않을까..?


public dataset
- 데이터를 어디서 가져올지
- 프로젝트 내용을 슬슬 물어봐야할 것 같음.


- 인공지능 대학원 
- 30분정도는 공유, 나머지는 수다
- 추천도 transfer learning자주 사용함


- 생명과학/ SW
- 바이오인포메틱스
- 비전/nlp하다가
- 모더레이터 한 주에 한번
- 2~3기 이야기 : 도메인이 확실, 추천은 최종프로젝트에서 데이터를 얻는데 어려움.
- gpt plus 

사전 질문 + 매주 수업내용에 따라 면접내용 같은거



- 진학목적
- 금요일에 한 주제를 정해서 발표
- 

Q&A 느낌


오프라인 
- 갈지말지?




# 오피스아워(금)
convolution을 self attention바꾸는 노력은 했으나, vit이후 사용

## vit
장점
- q,k,v로 인해 확장성이 낮았지만
- 기존 트랜스포머의 변경을 최소화
- 많은 데이터 처리가 가능하다(saturation)
단점
- cnn보다 inductive bias가 부족 --> 더 많은 데이터
	- 처음보는 데이터에 대한 clue
- cnn은 translation equivariance와 licality를 가정



VA
- 각각의 분포에서
- 랜덤으로 점을찍는다(sampling)
- 무작위로 점을찍게되면 의미없는 이미지가 나올 확률이 높음(노이즈)

샘플링을 가능하게 하려면 continuous region으로 만들어야함
- 각 distribution을 공간안에 합치는 개념
- 그 결과 생성모델의 역할도 할 수 있음.

latent space를 정규분포로 지정
-> 차원을 미리 제한

AAE의 아이디어
- GAN의 고품질 이미지 + VAE의 생성 이미지 제한

- Encoder : 인풋을 가우시안을 따르는 latent space로 인코딩
- Decoder  : latent space에서 새로운 이미지 생성
- Discriminator : 신경망이 생성한 이미지가 진짜인지 판단
	- 0 or 1
	- encoder의 z와 prior 분포의 z'을 비교

Loss : reconstruction loss
Adversarial loss 
Overall loss : $L_recon$ + $\lambda$$L_adv$


## 공부하는 방법?
- 이론을 잘 이해한 상태에서 정답을 봐야한다면 보고 문제를 풀어본 후 다시 안보고 풀어보기 
- 가정은 이론을 잘 이해했다는 것.



## 랩업리포트(금요일)
- 옵시디언 자료 [깃헙](https://github.com/tldbs5026/Study_Space)에.
- [여기](https://www.boostcourse.org/boostcampaitech6/forums/384196)에  댓글로 올리기




## 회고록
- 오늘하루 배웠던 것에 대한 간단한 정리
- 체크아웃하고 자기전에 작성하고 자기
- 이거는 학습정리용
- 내용과 관련된 것보다는 감상
- 매주 금요일에 대표 혹은 통합하여 제출