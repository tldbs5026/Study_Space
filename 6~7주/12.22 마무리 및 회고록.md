

# 오늘까지 마무리 할 일
- 강의 최종정리
- wrapup report 개인부분
- github에 최종안 올리고 pr

# 내일 할 일
- 주말동안 정리
- 추가적인 공부
- refactoring 어느정도 진행

# 공부하면서 내용 정리

Memory_based CF
- 사용자, 아이템 간의 상호작용 데이터를 기반으로 추천
WDN
- Model Based
	- 최적화, 훈련이 필요
	- SVD, FFM, FM, ALS, 그외 WDN,DCN, DeepCoNN 등
K-Means는 클러스터링


콜드 스타트 해결
- 사용자 프로파일을 바탕으로 하는 userbased cf
- 인기 있는 항목을 추천

파생변수 -> 과적합 가능성
- 이를 바탕으로 고도화는 지양하는 편이 좋음

ALS
- 사용자, 아이템을 번갈아 고정함
- FM은 행렬 계산이 아님
- Gradient Descent를 사용하지 않음

FM
- 기존의 kN^2에서 kn으로 변경

```
Class DeepCrossNetWork(nn.Module) :
	def __init__(self, input_dim, output_dim, num_layers, hidden_dim) :
	super(DeepCrossNetWork, self).__init__()
	self.cross_layers = nn.ModuleList(
	[nn.Linear(input_dim, input_dim) for _ in range(num_layers)])
	self.deep_layers = nn.ModuleList()

	for idx in range(num_layers) :
	self.deep_layers.extend([
		nn.Linear(input_dim, hidden_dim) if idx == 0 else nn.Linear(hidden_dim, hidden_dim),
		nn.BatchNorm1d(hidden_dim),
		nn.ReLu(),
		nn.Dropout(0.3)
		])
	self.output_layer = nn.Linear(hidden_dim, output_dim, bias=True)

	def forward(self, x0) :
	cross = x0
	for cross_layer in self.cross_layers :
		x = cross_layer(cross)
		cross = (x * x0) + cross
	deep = cross
	for deep_layers in self.deep_layers :
		deep = deep_layers(deep)
	output = self.output_layer(deep)
	return output
```


# 회고록
대회가 끝나고, 다들 마무리 짓는 분위기이다. 아직 남은 부분이 있고, 아쉬운 점도 남아있다. 2주동안 잠을 줄이고, 토론하고, 작업을 하였기 때문에 조금은 쉬어도 괜찮을 것 같다고 생각한다. 캐글대회에 참가했었지만, 이런 대회를 팀으로 나가는 것은 처음이고, 이런저런 세팅을 하는 것도 처음이라 상당한 시간을 소모하여 느긋하게 하지 못했던 것 같아서 아쉽다고 생각한다. 대회가 끝나고 아 이것도 했어야 했는데, 멘토링 시간에 멘토님의 말씀을 듣고 아 이것도 했어야했지 하는 생각만 계속남았고, 모델 한 두개 진득하게 돌릴 시간을 할애하지 못해서 조금만 더 다듬었으면 좋은 결과를 낳았을텐데 하는 아쉬움 또한 계속 남는다. 하지만 이러한 몰아치는 경험도 있으면 좋다고 생각한다. 현업에서 일을 하다보면 급박하게 처리해야할 태스크가 쌓이기 마련이다. 이럴때 이런 경험을 바탕으로 당황하지 않고 주어진 시간을 최대한 할애하여 처리하는 능력도 필요하다고 생각한다. 