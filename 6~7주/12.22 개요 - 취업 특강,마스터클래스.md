# 데일리 스크럼
- 족발, 만두, 짬뽕, 칼국수, 찐빵

강의, wrap up report

월요일에 각자 만들어 놓은 리포트를 합치기.
- 화요일 14시
- 미리 승아님께 보내주시면 통합.

개인회고
- 작성해보기



# 취업 특강

LLM 가속화

## computation
- 컴퓨터가 잘하는 것과 못하는 것을 구분

컴퓨터가 잘하는 것
- computation
	- 무어의 법칙
- 검색엔진
	- Fact를 아는 직업은 불리해질 것.
- multi tasking
	- 여러가지 일을 동시, scale-out의 가능성
- 24/1 operation
	- 쉬지않음

못하는 것
- 정답 없는 문제 풀기
	- 예술?
- 사실 관계 추론, 의사결정
	- 비즈니스 부분
- 사람이 해야 의미있는 일
	- 스포츠
- 공감 등
	- 상담과 같은

문학 번역 vs 법률 번역
- 법률은 metric
- 문학은 감성
- 컴퓨터와 공존하는 직업

## AI 엔지니어

1. 나에 대한 이해
- fundamenmtal한 학문을 좋아하는가?
- 결과가 나오지 않아도 꾸준히 파는 인내심
- AI/ML + 그 과정에서 발생하는 웹프로그래밍, 전처리등을 기꺼이 할 것인가?
	- 종합하면 연구자도 괜찮음
- 비즈니스 관심
- 실생활 변화를 좋아하는가?
- 모델링 + 웹프로그래밍 + 전처리
	- 종합하면 엔지니어도 괜찮음

2. 일찍 시작, 다양한 경험
- 학교 다니는 동안 관련 인턴/아르바이트/RA 권장
	- 지식을 활용하고, 사회에 영향을 주는 단계
	- thought experiment보다 더 옵션 탐색하는데 효과적
	- 각 포지션의 차이에 대한 이해
	- 각 조직이 하는일을 체감
	- 일하는 방법
		- 목표, 고객, 일정처리..
- 첫 선택이 마지막 선택이 아님
- 하나의 기회가 다른 기회의 문을 염
	- 좋은 인상 -> 나중에 추천서
- 주어진 기회가 좋은 기회인지는 지나고 나서야 알 수 있음.
	- 기회가 주어졌을 때 많은 시도를 해봐야함.

3. 경험, converge
- 나에게 더 잘 맞는 기회를 솎을 수 있음
- 커리어 사다리는 일방이 아님.

엔지니어 -> 제품 조직화와 같은


## 좋은 자리를 구하기 어렵..

AI Competition
- 포럼
- hands-on으로 문제를 풀어보는 것




최신논문 재현
- 논문을 구현하는데 요구되는 백그라운드 지식 필요
- display and selling

학위?
- Nope
- 다양한 곳에 지원, 성할 수 있는 환경 선택
	- 배울 수 있는 멘토
	- 데이터/계산 자원
	- 집중할 수 있는 문화


비전공자가 불리할까?
- Nope
- 실력
- 전공자 == 기대감
	- 기대감 == 코테, 인터뷰

나이?
- Nope
- 장벽이 될 수 있는 것은 
	- 기존 경력의 여부, 기대 연봉
	- 기존 경력이 어떻게 도움이 되는가를 selling
	- 연봉에 대한 selling

배워야하는 것?
- 필요한 때 배우면된다
- fundamental은 검증되어야함.
	- 코테, 수학, ai지식
	- 사고, 추론 == fundamental한 지식

역량?
- 일 잘하는 사람
	- ai 지식
	- 커뮤니케이션
	- 일처리 빠르고 꼼꼼한 사람
- 하드스킬
	- 공학, sw 엔지니어링
	- sw가 부족하면 ai 이론등에 특화
- 소프트스킬
	- 관계

역량을 어떻게 보여줘야할까?
- 팀으로 일하기 때문에 하나만 잘하면됨
- 해봤어요 보다는 성과를 얻었음
- 하드스킬
	- coding compe 입상
	- kaggle등에서 수상
	- publication record
	- 서비스 경력
	- 다른 회사 경력

기술 블로그?
- 지식을 나만의 언어로 정리
- 블로그를 통한 소통
	- 강점을 보여주기
	- 임팩트 있는 블로그
- 깃헙/오픈소스도 마찬가지


## 팀내 역할
- 대부분 경우 모델링은 일부
- 팀 내 다양한 역할에 맞춰서 진행
- 일반적으로 공지되는 포지션과는 다른

모델 학습, 평가 개선 + 논문
리서치에 특화
	논문 읽기
	세미나
	프로토타이핑

경쟁사의 논문을 재현/벤치마크 결과물

data/model 배관공

얕고 넓음
- 비즈니스, 모델링, 웹개발..

경량화, 최적화를 위한 low level

...

## summary
- 같은 직무라도 관련 역할이 다양하기 때문에 공고를 확인
- 100% 하나의 역할은 못함.
	- 모든 것을 다 잘할 필요보다는 강점
	- 관심사 + 시장의 흐름 파악

100을 가지고 있으면 120으로 마케팅하라.


코딩보다 데이터 구축, 서류 작업 등을 더 많이 할 수 있다
- ai엔지니어의 본질은 문제 정의, 기술의 병목을 뚫는 것.


이직의 이유
- 노력 대비 임팩트

성과측정
- 사바사
- 비즈니스에 영향

스타트업 지표
- 성장가능성

포트폴리오 이력
- 대회
- 양보다는 질

좁은 범위?
- 회사와의 합의
- 범위는 수요에 따라
	- 경량화


 
data
algorithm





# 스페셜 피어세션


- 하고싶었던 사람이 있어서
- 마지막날에 모델을 섞으면서 마무리

- 결측치
	- 실험적으로 잘나온 것.
	- country로만 FFM기준으로 0.02
	- 하이퍼파라미터 맞춰서 돌리니까 2.16
- FFM + Deep느낌으로 해보고
- weight decay가 영향이 컸음.
- 


- DeepCoNN, CNN_FM에서 임베딩
	- 합친후, autoencoder
	- 새로 층 쌓아서 MLP
- CatBoost
- 하이퍼파라미터만 계속


- valid loss의 흐름
- bert uncased pretrained가 가장 좋았음.
- DeepCoNN feature가 생성되고 output
	- feature를 가져오고, 
	- cnn-fm의 feature
	- (batch *2) + user +
		- batch만 맞추고 나머지는 concat
- optimizer




- DeepCoNN
	- Bert 가 안써져서
- 결측치 처리
	- 카테고리 - 400개정도에서 50개 정도로
	- 빈도위주
	- age 범주화 - 국가의 평균
	- summary는 title
	- country는 baseline
	- language - isbn
		- 앞 두자리가 국가코드니까 그걸로 채움
- 단순한 데이터라서 최대한 단순하게 진행하는 것이 가장 효율적이었을 것.
- lr + 스케쥴러



- FM
- DCN WDN
- 마지막 앙상블
- 결측치, 전처리 위주
- 
cnn_fm 
- context를 활용하지 않았다.
- user_idx와 book_idx만의 상호작용을 보았다
- context를 넣는 것이 더 좋은 해석을 할 것이다.
- linear가 mlp보다 더 관측이 잘됐다.

## 깃허브?
- pr 
- 전처리에서 merge 할 수 잇는 부분은 하고
- branch관리?
	- file, code를 긁어서 전송

- 구글드라이브



프리랜서
- 부캠과정을 거친 사람 소개, 조언, 면접질문 목록 등
- 경험



ncf + ffm + catboost
- 두명의 catboost를 섞음
	- catboost 7개 섞은 모델 

catboost 2+ cnn_fm + dcn
- cnn계열에서 맞춘 데이터 + dcn

stacking ensemble
- 서로의 가중치 학습

cnn_fm : 2.14까지
- feature 추가
- hyperparameter optimizer_sgd


dcn

fm + dcn
- 

해석
- 너무 단순하다


# 마스터클래스

- EDA를 기반으로 분포, 카테고리 개수 등을 기준으로 insight


isbn
- country

anova